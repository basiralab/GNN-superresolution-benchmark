{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from model import *\n",
    "from processing import *\n",
    "from train_paper import *\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from evaluation import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sympy import fu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data paths for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_1_LR_PATH = 'RandomCV/Train/Fold1/lr_split_1.csv'\n",
    "SPLIT_1_HR_PATH = 'RandomCV/Train/Fold1/hr_split_1.csv'\n",
    "SPLIT_2_LR_PATH = 'RandomCV/Train/Fold2/lr_split_2.csv'\n",
    "SPLIT_2_HR_PATH = 'RandomCV/Train/Fold2/hr_split_2.csv'\n",
    "SPLIT_3_LR_PATH = 'RandomCV/Train/Fold3/lr_split_3.csv'\n",
    "SPLIT_3_HR_PATH = 'RandomCV/Train/Fold3/hr_split_3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "    epochs = 500\n",
    "    lr = 0.0001\n",
    "    lmbda = 0.1\n",
    "    lr_dim = 160\n",
    "    hr_dim = 320\n",
    "    hidden_dim = 640\n",
    "    padding = 26\n",
    "    double_convolution = True\n",
    "    dropout = 0.1\n",
    "    weight_decay = 0\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "SEED = 42\n",
    "GET_METRICS = True\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load Data\n",
    "split_1_adj, split_1_ground_truth = load_matrix_data(SPLIT_1_LR_PATH, SPLIT_1_HR_PATH, 93)\n",
    "split_2_adj, split_2_ground_truth = load_matrix_data(SPLIT_2_LR_PATH, SPLIT_2_HR_PATH, 93)\n",
    "split_3_adj, split_3_ground_truth = load_matrix_data(SPLIT_3_LR_PATH, SPLIT_3_HR_PATH, 93)\n",
    "\n",
    "print(\"DATA LOADED\")\n",
    "\n",
    "fold_results = []\n",
    "train_losses_all_with_val = []\n",
    "val_losses_all_with_val = []\n",
    "train_losses_all_no_val = []\n",
    "\n",
    "# Run 3-fold CV\n",
    "for i in range(3):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    \n",
    "    # Determine train, validation, and test splits\n",
    "    if i == 0:\n",
    "        train_adj = torch.cat((split_2_adj[:-20], split_3_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_2_ground_truth[:-20], split_3_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_2_adj[-20:], split_3_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_2_ground_truth[-20:], split_3_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_1_adj\n",
    "        test_ground_truth = split_1_ground_truth\n",
    "    elif i == 1:\n",
    "        train_adj = torch.cat((split_1_adj[:-20], split_3_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_1_ground_truth[:-20], split_3_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_1_adj[-20:], split_3_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_1_ground_truth[-20:], split_3_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_2_adj\n",
    "        test_ground_truth = split_2_ground_truth\n",
    "    else:\n",
    "        train_adj = torch.cat((split_1_adj[:-20], split_2_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_1_ground_truth[:-20], split_2_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_1_adj[-20:], split_2_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_1_ground_truth[-20:], split_2_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_3_adj\n",
    "        test_ground_truth = split_3_ground_truth\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SuperBLTGraph(args)\n",
    "    \n",
    "    train_labels = create_discrepancy(train_ground_truth, zero_shift=-0.05)\n",
    "    \n",
    "    # Train model\n",
    "    train_losses, val_losses, best_epoch, lr_schedule = train(model, train_adj, train_labels, args, val_adj, val_ground_truth)\n",
    "    train_losses_all_with_val.append(train_losses)\n",
    "    val_losses_all_with_val.append(val_losses)\n",
    "\n",
    "    # Get metrics for the left-out fold\n",
    "    test_outputs = compute_output_hr(args, test_adj, model)\n",
    "    metrics = evaluate_all(test_ground_truth.detach().numpy(), test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for each fold\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_all_with_val[i], label='Training Loss')\n",
    "    plt.plot(val_losses_all_with_val[i], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {i+1} - Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for each fold\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_all_no_val[i], label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {i+1} - Training Loss (No Validation)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df = pd.read_csv('ID-randomCV.csv', index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add row averaging and std columns except for the first column and top row\n",
    "identity_df.loc['mean'] = identity_df.mean()\n",
    "identity_df.loc['std'] = identity_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "identity_df.to_csv('01-randomCV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClusterCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data paths for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_1_LR_PATH = 'Cluster-CV/Fold1/lr_clusterA.csv'\n",
    "SPLIT_1_HR_PATH = 'Cluster-CV/Fold1/hr_clusterA.csv'\n",
    "SPLIT_2_LR_PATH = 'Cluster-CV/Fold2/lr_clusterB.csv'\n",
    "SPLIT_2_HR_PATH = 'Cluster-CV/Fold2/hr_clusterB.csv'\n",
    "SPLIT_3_LR_PATH = 'Cluster-CV/Fold3/lr_clusterC.csv'\n",
    "SPLIT_3_HR_PATH = 'Cluster-CV/Fold3/hr_clusterC.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "    epochs = 500\n",
    "    lr = 0.0001\n",
    "    lmbda = 0.1\n",
    "    lr_dim = 160\n",
    "    hr_dim = 320\n",
    "    hidden_dim = 640\n",
    "    padding = 26\n",
    "    double_convolution = True\n",
    "    dropout = 0.1\n",
    "    weight_decay = 0\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "SEED = 42\n",
    "GET_METRICS = True\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load Data\n",
    "split_1_adj, split_1_ground_truth = load_matrix_data(SPLIT_1_LR_PATH, SPLIT_1_HR_PATH, 103)\n",
    "split_2_adj, split_2_ground_truth = load_matrix_data(SPLIT_2_LR_PATH, SPLIT_2_HR_PATH, 103)\n",
    "split_3_adj, split_3_ground_truth = load_matrix_data(SPLIT_3_LR_PATH, SPLIT_3_HR_PATH, 76)\n",
    "\n",
    "print(\"DATA LOADED\")\n",
    "\n",
    "fold_results = []\n",
    "train_losses_all_with_val = []\n",
    "val_losses_all_with_val = []\n",
    "train_losses_all_no_val = []\n",
    "\n",
    "# Run 3-fold CV\n",
    "for i in range(3):\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    \n",
    "    # Determine train, validation, and test splits\n",
    "    if i == 0:\n",
    "        train_adj = torch.cat((split_2_adj[:-20], split_3_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_2_ground_truth[:-20], split_3_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_2_adj[-20:], split_3_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_2_ground_truth[-20:], split_3_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_1_adj\n",
    "        test_ground_truth = split_1_ground_truth\n",
    "    elif i == 1:\n",
    "        train_adj = torch.cat((split_1_adj[:-20], split_3_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_1_ground_truth[:-20], split_3_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_1_adj[-20:], split_3_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_1_ground_truth[-20:], split_3_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_2_adj\n",
    "        test_ground_truth = split_2_ground_truth\n",
    "    else:\n",
    "        train_adj = torch.cat((split_1_adj[:-20], split_2_adj[:-20]), dim=0)\n",
    "        train_ground_truth = torch.cat((split_1_ground_truth[:-20], split_2_ground_truth[:-20]), dim=0)\n",
    "        val_adj = torch.cat((split_1_adj[-20:], split_2_adj[-20:]), dim=0)\n",
    "        val_ground_truth = torch.cat((split_1_ground_truth[-20:], split_2_ground_truth[-20:]), dim=0)\n",
    "        test_adj = split_3_adj\n",
    "        test_ground_truth = split_3_ground_truth\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SuperBLTGraph(args)\n",
    "    \n",
    "    train_labels = create_discrepancy(train_ground_truth, zero_shift=-0.05)\n",
    "    \n",
    "    # Train model\n",
    "    train_losses, val_losses, best_epoch, lr_schedule = train(model, train_adj, train_labels, args, val_adj, val_ground_truth)\n",
    "    train_losses_all_with_val.append(train_losses)\n",
    "    val_losses_all_with_val.append(val_losses)\n",
    "\n",
    "   # Retrain model on full training set (without validation)\n",
    "    full_train_adj = torch.cat((train_adj, val_adj), dim=0)\n",
    "    full_train_ground_truth = torch.cat((train_ground_truth, val_ground_truth), dim=0)\n",
    "    \n",
    "    model = SuperBLTGraph(args)\n",
    "    train_labels = create_discrepancy(full_train_ground_truth, zero_shift=-0.05)\n",
    "\n",
    "    train_losses = retrain_model(model, full_train_adj, full_train_ground_truth, args, lr_schedule, best_epoch)\n",
    "    train_losses_all_no_val.append(train_losses)\n",
    "    \n",
    "    # Get metrics for the left-out fold\n",
    "    test_outputs = compute_output_hr(args, test_adj, model)\n",
    "    metrics = evaluate_all(test_ground_truth.detach().numpy(), test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for each fold\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_all_with_val[i], label='Training Loss')\n",
    "    plt.plot(val_losses_all_with_val[i], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {i+1} - Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots for each fold\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses_all_no_val[i], label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {i+1} - Training Loss (No Validation)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df = pd.read_csv('ID-randomCV.csv', index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add row averaging and std columns except for the first column and top row\n",
    "identity_df.loc['mean'] = identity_df.mean()\n",
    "identity_df.loc['std'] = identity_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "identity_df.to_csv('01-clusterCV.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_cw2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
